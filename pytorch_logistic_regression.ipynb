{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_logistic_regression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression"
      ],
      "metadata": {
        "id": "iiHA25AQAB7p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1BT3e7I-puB",
        "outputId": "5c4ccbcd-8d23-44d2-94b0-73f5c471137a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f63ed7e4770>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.manual_seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_data = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]]\n",
        "y_data = [[0], [0], [0], [1], [1], [1]]\n",
        "x_train = torch.FloatTensor(x_data)\n",
        "y_train = torch.FloatTensor(y_data)"
      ],
      "metadata": {
        "id": "5buU0ec-AJ2y"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90pU3OWBANY2",
        "outputId": "32138579-f83e-4c80-a973-96ee4e1f869f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([6, 2])\n",
            "torch.Size([6, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W = torch.zeros((2,1),requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "\n",
        "hypothesis = 1/(1+torch.exp(-(x_train.matmul(W))+b))"
      ],
      "metadata": {
        "id": "V6-mp-ehAXDz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(hypothesis)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlH7DAYeAkOR",
        "outputId": "b68ebc52-8ac0-433c-ffd9-9318afa695a6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000]], grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pytorch에서는 sigmoid 함수 제공\n",
        "hypothesis = torch.sigmoid(x_train.matmul(W)+b)\n",
        "print(hypothesis)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-zYWuLKAlus",
        "outputId": "d6acd6fe-9da2-4dd2-ead7-d563d3fc651e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000]], grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 오차 구하기\n",
        "losses = -(y_train*torch.log(hypothesis)+(1-y_train)*torch.log(1-hypothesis))\n",
        "print(losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABda8RFcAtMR",
        "outputId": "6d0d9559-4218-4057-db9a-a11312df1928"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6931],\n",
            "        [0.6931],\n",
            "        [0.6931],\n",
            "        [0.6931],\n",
            "        [0.6931],\n",
            "        [0.6931]], grad_fn=<NegBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cost = losses.mean()\n",
        "print(cost)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJvLtY_oBDF_",
        "outputId": "dd13992e-3fa5-4eaa-af46-1bddeb1a9f79"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.6931, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pytorch에서는 logistic regression의 cost 함수를 제공함\n",
        "F.binary_cross_entropy(hypothesis, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTOCBpdoBGTG",
        "outputId": "cb52199f-48b3-4841-c6be-4b04d04f8c11"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 전체 코드\n",
        "x_data = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]]\n",
        "y_data = [[0], [0], [0], [1], [1], [1]]\n",
        "x_train = torch.FloatTensor(x_data)\n",
        "y_train = torch.FloatTensor(y_data)\n",
        "\n",
        "W = torch.zeros((2,1),requires_grad=True)\n",
        "b = torch.zeros(1,requires_grad=True)\n",
        "\n",
        "optimizer = optim.SGD([W,b],lr=1)\n",
        "\n",
        "nb_epochs = 1000\n",
        "\n",
        "for epoch in range(nb_epochs+1):\n",
        "  hypothesis = torch.sigmoid(x_train.matmul(W)+b)\n",
        "  # re = 1-hypothesis\n",
        "  cost = -(y_train*torch.log(hypothesis)+(1-y_train)*torch.log(1-hypothesis)).mean()\n",
        "  \n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch%100==0:\n",
        "    print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
        "            epoch, nb_epochs, cost.item()\n",
        "        ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwxbwOWhBQWc",
        "outputId": "598e9255-81e9-47b9-9e6c-e15d6555a318"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/1000 Cost: 0.693147\n",
            "Epoch  100/1000 Cost: 0.134722\n",
            "Epoch  200/1000 Cost: 0.080643\n",
            "Epoch  300/1000 Cost: 0.057900\n",
            "Epoch  400/1000 Cost: 0.045300\n",
            "Epoch  500/1000 Cost: 0.037261\n",
            "Epoch  600/1000 Cost: 0.031673\n",
            "Epoch  700/1000 Cost: 0.027556\n",
            "Epoch  800/1000 Cost: 0.024394\n",
            "Epoch  900/1000 Cost: 0.021888\n",
            "Epoch 1000/1000 Cost: 0.019852\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hypothesis = torch.sigmoid(x_train.matmul(W)+b)\n",
        "print(hypothesis)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUJCruSgCeVy",
        "outputId": "a668a91b-23bb-42aa-b425-af9c2af898c8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2.7648e-04],\n",
            "        [3.1608e-02],\n",
            "        [3.8977e-02],\n",
            "        [9.5622e-01],\n",
            "        [9.9823e-01],\n",
            "        [9.9969e-01]], grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = hypothesis >=torch.FloatTensor([0.5])\n",
        "\n",
        "print(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uvjkmmJClQb",
        "outputId": "f0c97bf5-e93f-452f-b649-2d23f67e29b6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[False],\n",
            "        [False],\n",
            "        [False],\n",
            "        [ True],\n",
            "        [ True],\n",
            "        [ True]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(W,b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6frRiF-CynY",
        "outputId": "e3fdb380-575c-4d8c-f791-c12770c54f53"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[3.2530],\n",
            "        [1.5179]], requires_grad=True) tensor([-14.4819], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# nn.Module로 구현"
      ],
      "metadata": {
        "id": "9zmKQBDpDvuX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.manual_seed(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7knbpxPC28j",
        "outputId": "96eba934-254c-4ad2-e4d3-702c1f78ccd6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f63ed7e4770>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_data = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]]\n",
        "y_data = [[0], [0], [0], [1], [1], [1]]\n",
        "x_train = torch.FloatTensor(x_data)\n",
        "y_train = torch.FloatTensor(y_data)\n",
        "\n",
        "# nn.Sequential()은 nn.Module 층을 차례로 쌓을 수 있도록 함\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(2,1), # input_dim =2, output_dim = 1\n",
        "    nn.Sigmoid() # 출력함수는 sigmoid\n",
        ")\n",
        "\n",
        "model(x_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqIokeyjD6pW",
        "outputId": "e9a899b1-1222-4f58-fa27-16a5d0b3a1a3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4020],\n",
              "        [0.4147],\n",
              "        [0.6556],\n",
              "        [0.5948],\n",
              "        [0.6788],\n",
              "        [0.8061]], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## tensor에 저장된 값만 가져오려면 item() 써서 가져오기"
      ],
      "metadata": {
        "id": "DN8JfjN_Fi_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(model.parameters(),lr=1)\n",
        "\n",
        "nb_epochs=1000\n",
        "for epoch in range(nb_epochs+1):\n",
        "  hypo = model(x_train)\n",
        "\n",
        "  cost = F.binary_cross_entropy(hypo,y_train)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch%10==0:\n",
        "    prediction = hypo >= torch.FloatTensor([0.5]) # 예측값이 0.5이상이면 True\n",
        "\n",
        "    correct_pred = prediction.float() == y_train\n",
        "\n",
        "    accu = correct_pred.sum().item()/len(correct_pred)\n",
        "\n",
        "    print('Epoch {:4d}/{} Cost: {:.6f} Accuracy {:2.2f}%'.format( # 각 에포크마다 정확도를 출력\n",
        "            epoch, nb_epochs, cost.item(), accu * 100,\n",
        "        ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPiE5mH3ET0Q",
        "outputId": "7f7207e2-3b22-4c6e-d923-5b5010c46262"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/1000 Cost: 0.527002 Accuracy 83.33%\n",
            "Epoch   10/1000 Cost: 0.994596 Accuracy 66.67%\n",
            "Epoch   20/1000 Cost: 0.570399 Accuracy 83.33%\n",
            "Epoch   30/1000 Cost: 0.473909 Accuracy 83.33%\n",
            "Epoch   40/1000 Cost: 0.388606 Accuracy 83.33%\n",
            "Epoch   50/1000 Cost: 0.307901 Accuracy 83.33%\n",
            "Epoch   60/1000 Cost: 0.235923 Accuracy 83.33%\n",
            "Epoch   70/1000 Cost: 0.182916 Accuracy 100.00%\n",
            "Epoch   80/1000 Cost: 0.155795 Accuracy 100.00%\n",
            "Epoch   90/1000 Cost: 0.143031 Accuracy 100.00%\n",
            "Epoch  100/1000 Cost: 0.133369 Accuracy 100.00%\n",
            "Epoch  110/1000 Cost: 0.124978 Accuracy 100.00%\n",
            "Epoch  120/1000 Cost: 0.117600 Accuracy 100.00%\n",
            "Epoch  130/1000 Cost: 0.111060 Accuracy 100.00%\n",
            "Epoch  140/1000 Cost: 0.105223 Accuracy 100.00%\n",
            "Epoch  150/1000 Cost: 0.099983 Accuracy 100.00%\n",
            "Epoch  160/1000 Cost: 0.095251 Accuracy 100.00%\n",
            "Epoch  170/1000 Cost: 0.090958 Accuracy 100.00%\n",
            "Epoch  180/1000 Cost: 0.087044 Accuracy 100.00%\n",
            "Epoch  190/1000 Cost: 0.083461 Accuracy 100.00%\n",
            "Epoch  200/1000 Cost: 0.080169 Accuracy 100.00%\n",
            "Epoch  210/1000 Cost: 0.077132 Accuracy 100.00%\n",
            "Epoch  220/1000 Cost: 0.074323 Accuracy 100.00%\n",
            "Epoch  230/1000 Cost: 0.071717 Accuracy 100.00%\n",
            "Epoch  240/1000 Cost: 0.069291 Accuracy 100.00%\n",
            "Epoch  250/1000 Cost: 0.067029 Accuracy 100.00%\n",
            "Epoch  260/1000 Cost: 0.064912 Accuracy 100.00%\n",
            "Epoch  270/1000 Cost: 0.062929 Accuracy 100.00%\n",
            "Epoch  280/1000 Cost: 0.061066 Accuracy 100.00%\n",
            "Epoch  290/1000 Cost: 0.059312 Accuracy 100.00%\n",
            "Epoch  300/1000 Cost: 0.057659 Accuracy 100.00%\n",
            "Epoch  310/1000 Cost: 0.056098 Accuracy 100.00%\n",
            "Epoch  320/1000 Cost: 0.054620 Accuracy 100.00%\n",
            "Epoch  330/1000 Cost: 0.053220 Accuracy 100.00%\n",
            "Epoch  340/1000 Cost: 0.051892 Accuracy 100.00%\n",
            "Epoch  350/1000 Cost: 0.050630 Accuracy 100.00%\n",
            "Epoch  360/1000 Cost: 0.049428 Accuracy 100.00%\n",
            "Epoch  370/1000 Cost: 0.048284 Accuracy 100.00%\n",
            "Epoch  380/1000 Cost: 0.047193 Accuracy 100.00%\n",
            "Epoch  390/1000 Cost: 0.046150 Accuracy 100.00%\n",
            "Epoch  400/1000 Cost: 0.045154 Accuracy 100.00%\n",
            "Epoch  410/1000 Cost: 0.044200 Accuracy 100.00%\n",
            "Epoch  420/1000 Cost: 0.043287 Accuracy 100.00%\n",
            "Epoch  430/1000 Cost: 0.042411 Accuracy 100.00%\n",
            "Epoch  440/1000 Cost: 0.041571 Accuracy 100.00%\n",
            "Epoch  450/1000 Cost: 0.040764 Accuracy 100.00%\n",
            "Epoch  460/1000 Cost: 0.039988 Accuracy 100.00%\n",
            "Epoch  470/1000 Cost: 0.039241 Accuracy 100.00%\n",
            "Epoch  480/1000 Cost: 0.038523 Accuracy 100.00%\n",
            "Epoch  490/1000 Cost: 0.037830 Accuracy 100.00%\n",
            "Epoch  500/1000 Cost: 0.037163 Accuracy 100.00%\n",
            "Epoch  510/1000 Cost: 0.036519 Accuracy 100.00%\n",
            "Epoch  520/1000 Cost: 0.035897 Accuracy 100.00%\n",
            "Epoch  530/1000 Cost: 0.035296 Accuracy 100.00%\n",
            "Epoch  540/1000 Cost: 0.034716 Accuracy 100.00%\n",
            "Epoch  550/1000 Cost: 0.034154 Accuracy 100.00%\n",
            "Epoch  560/1000 Cost: 0.033611 Accuracy 100.00%\n",
            "Epoch  570/1000 Cost: 0.033085 Accuracy 100.00%\n",
            "Epoch  580/1000 Cost: 0.032575 Accuracy 100.00%\n",
            "Epoch  590/1000 Cost: 0.032081 Accuracy 100.00%\n",
            "Epoch  600/1000 Cost: 0.031602 Accuracy 100.00%\n",
            "Epoch  610/1000 Cost: 0.031137 Accuracy 100.00%\n",
            "Epoch  620/1000 Cost: 0.030686 Accuracy 100.00%\n",
            "Epoch  630/1000 Cost: 0.030248 Accuracy 100.00%\n",
            "Epoch  640/1000 Cost: 0.029822 Accuracy 100.00%\n",
            "Epoch  650/1000 Cost: 0.029408 Accuracy 100.00%\n",
            "Epoch  660/1000 Cost: 0.029006 Accuracy 100.00%\n",
            "Epoch  670/1000 Cost: 0.028615 Accuracy 100.00%\n",
            "Epoch  680/1000 Cost: 0.028234 Accuracy 100.00%\n",
            "Epoch  690/1000 Cost: 0.027864 Accuracy 100.00%\n",
            "Epoch  700/1000 Cost: 0.027503 Accuracy 100.00%\n",
            "Epoch  710/1000 Cost: 0.027151 Accuracy 100.00%\n",
            "Epoch  720/1000 Cost: 0.026808 Accuracy 100.00%\n",
            "Epoch  730/1000 Cost: 0.026474 Accuracy 100.00%\n",
            "Epoch  740/1000 Cost: 0.026149 Accuracy 100.00%\n",
            "Epoch  750/1000 Cost: 0.025831 Accuracy 100.00%\n",
            "Epoch  760/1000 Cost: 0.025521 Accuracy 100.00%\n",
            "Epoch  770/1000 Cost: 0.025218 Accuracy 100.00%\n",
            "Epoch  780/1000 Cost: 0.024923 Accuracy 100.00%\n",
            "Epoch  790/1000 Cost: 0.024635 Accuracy 100.00%\n",
            "Epoch  800/1000 Cost: 0.024353 Accuracy 100.00%\n",
            "Epoch  810/1000 Cost: 0.024077 Accuracy 100.00%\n",
            "Epoch  820/1000 Cost: 0.023808 Accuracy 100.00%\n",
            "Epoch  830/1000 Cost: 0.023545 Accuracy 100.00%\n",
            "Epoch  840/1000 Cost: 0.023287 Accuracy 100.00%\n",
            "Epoch  850/1000 Cost: 0.023036 Accuracy 100.00%\n",
            "Epoch  860/1000 Cost: 0.022789 Accuracy 100.00%\n",
            "Epoch  870/1000 Cost: 0.022548 Accuracy 100.00%\n",
            "Epoch  880/1000 Cost: 0.022312 Accuracy 100.00%\n",
            "Epoch  890/1000 Cost: 0.022081 Accuracy 100.00%\n",
            "Epoch  900/1000 Cost: 0.021855 Accuracy 100.00%\n",
            "Epoch  910/1000 Cost: 0.021633 Accuracy 100.00%\n",
            "Epoch  920/1000 Cost: 0.021416 Accuracy 100.00%\n",
            "Epoch  930/1000 Cost: 0.021203 Accuracy 100.00%\n",
            "Epoch  940/1000 Cost: 0.020994 Accuracy 100.00%\n",
            "Epoch  950/1000 Cost: 0.020790 Accuracy 100.00%\n",
            "Epoch  960/1000 Cost: 0.020589 Accuracy 100.00%\n",
            "Epoch  970/1000 Cost: 0.020393 Accuracy 100.00%\n",
            "Epoch  980/1000 Cost: 0.020200 Accuracy 100.00%\n",
            "Epoch  990/1000 Cost: 0.020010 Accuracy 100.00%\n",
            "Epoch 1000/1000 Cost: 0.019825 Accuracy 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model(x_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuYVRyBgE6C5",
        "outputId": "08cf06f2-f7ea-42b1-f73b-0bde6508a9da"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2.7553e-04],\n",
              "        [3.1567e-02],\n",
              "        [3.8923e-02],\n",
              "        [9.5627e-01],\n",
              "        [9.9824e-01],\n",
              "        [9.9969e-01]], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(model.parameters()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ile5wU8ZF0s8",
        "outputId": "30e60c61-884e-446b-c155-5da16fc20629"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Parameter containing:\n",
            "tensor([[3.2543, 1.5186]], requires_grad=True), Parameter containing:\n",
            "tensor([-14.4881], requires_grad=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sigmoid 함수는 ANN의 hidden layer에서는 거의 사용되지 않는다."
      ],
      "metadata": {
        "id": "p_nzGCRJF4YM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 클래스로 구현"
      ],
      "metadata": {
        "id": "aEkzgfXDGCy7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BinaryClassifier(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(2,1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.sigmoid(self.linear(x))\n",
        "\n",
        "x_data = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]]\n",
        "y_data = [[0], [0], [0], [1], [1], [1]]\n",
        "x_train = torch.FloatTensor(x_data)\n",
        "y_train = torch.FloatTensor(y_data)\n",
        "\n",
        "model = BinaryClassifier()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(),lr=1)\n",
        "\n",
        "nb_epochs=1000\n",
        "\n",
        "for epoch in range(nb_epochs+1):\n",
        "  hypo = model(x_train)\n",
        "\n",
        "  cost = F.binary_cross_entropy(hypo,y_train)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch%10==0:\n",
        "    pred = hypo>=torch.FloatTensor([0.5])\n",
        "\n",
        "    corr_pred = pred.float()==y_train\n",
        "\n",
        "    accu = corr_pred.sum().item()/len(corr_pred)\n",
        "\n",
        "    print('Epoch {:4d}/{} Cost: {:.6f} Accuracy {:2.2f}%'.format( # 각 에포크마다 정확도를 출력\n",
        "            epoch, nb_epochs, cost.item(), accu * 100,\n",
        "        ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mS50lrd0GEA_",
        "outputId": "94403c49-c054-499f-dae4-877d2140a438"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/1000 Cost: 0.614994 Accuracy 66.67%\n",
            "Epoch   10/1000 Cost: 0.747550 Accuracy 83.33%\n",
            "Epoch   20/1000 Cost: 0.633216 Accuracy 83.33%\n",
            "Epoch   30/1000 Cost: 0.538123 Accuracy 83.33%\n",
            "Epoch   40/1000 Cost: 0.450406 Accuracy 83.33%\n",
            "Epoch   50/1000 Cost: 0.366382 Accuracy 83.33%\n",
            "Epoch   60/1000 Cost: 0.287368 Accuracy 83.33%\n",
            "Epoch   70/1000 Cost: 0.219289 Accuracy 83.33%\n",
            "Epoch   80/1000 Cost: 0.173225 Accuracy 100.00%\n",
            "Epoch   90/1000 Cost: 0.151674 Accuracy 100.00%\n",
            "Epoch  100/1000 Cost: 0.140280 Accuracy 100.00%\n",
            "Epoch  110/1000 Cost: 0.131002 Accuracy 100.00%\n",
            "Epoch  120/1000 Cost: 0.122903 Accuracy 100.00%\n",
            "Epoch  130/1000 Cost: 0.115765 Accuracy 100.00%\n",
            "Epoch  140/1000 Cost: 0.109426 Accuracy 100.00%\n",
            "Epoch  150/1000 Cost: 0.103760 Accuracy 100.00%\n",
            "Epoch  160/1000 Cost: 0.098664 Accuracy 100.00%\n",
            "Epoch  170/1000 Cost: 0.094056 Accuracy 100.00%\n",
            "Epoch  180/1000 Cost: 0.089870 Accuracy 100.00%\n",
            "Epoch  190/1000 Cost: 0.086050 Accuracy 100.00%\n",
            "Epoch  200/1000 Cost: 0.082549 Accuracy 100.00%\n",
            "Epoch  210/1000 Cost: 0.079328 Accuracy 100.00%\n",
            "Epoch  220/1000 Cost: 0.076356 Accuracy 100.00%\n",
            "Epoch  230/1000 Cost: 0.073604 Accuracy 100.00%\n",
            "Epoch  240/1000 Cost: 0.071048 Accuracy 100.00%\n",
            "Epoch  250/1000 Cost: 0.068668 Accuracy 100.00%\n",
            "Epoch  260/1000 Cost: 0.066446 Accuracy 100.00%\n",
            "Epoch  270/1000 Cost: 0.064367 Accuracy 100.00%\n",
            "Epoch  280/1000 Cost: 0.062417 Accuracy 100.00%\n",
            "Epoch  290/1000 Cost: 0.060584 Accuracy 100.00%\n",
            "Epoch  300/1000 Cost: 0.058858 Accuracy 100.00%\n",
            "Epoch  310/1000 Cost: 0.057231 Accuracy 100.00%\n",
            "Epoch  320/1000 Cost: 0.055692 Accuracy 100.00%\n",
            "Epoch  330/1000 Cost: 0.054236 Accuracy 100.00%\n",
            "Epoch  340/1000 Cost: 0.052856 Accuracy 100.00%\n",
            "Epoch  350/1000 Cost: 0.051546 Accuracy 100.00%\n",
            "Epoch  360/1000 Cost: 0.050301 Accuracy 100.00%\n",
            "Epoch  370/1000 Cost: 0.049115 Accuracy 100.00%\n",
            "Epoch  380/1000 Cost: 0.047986 Accuracy 100.00%\n",
            "Epoch  390/1000 Cost: 0.046908 Accuracy 100.00%\n",
            "Epoch  400/1000 Cost: 0.045878 Accuracy 100.00%\n",
            "Epoch  410/1000 Cost: 0.044893 Accuracy 100.00%\n",
            "Epoch  420/1000 Cost: 0.043951 Accuracy 100.00%\n",
            "Epoch  430/1000 Cost: 0.043048 Accuracy 100.00%\n",
            "Epoch  440/1000 Cost: 0.042182 Accuracy 100.00%\n",
            "Epoch  450/1000 Cost: 0.041351 Accuracy 100.00%\n",
            "Epoch  460/1000 Cost: 0.040552 Accuracy 100.00%\n",
            "Epoch  470/1000 Cost: 0.039784 Accuracy 100.00%\n",
            "Epoch  480/1000 Cost: 0.039045 Accuracy 100.00%\n",
            "Epoch  490/1000 Cost: 0.038334 Accuracy 100.00%\n",
            "Epoch  500/1000 Cost: 0.037649 Accuracy 100.00%\n",
            "Epoch  510/1000 Cost: 0.036987 Accuracy 100.00%\n",
            "Epoch  520/1000 Cost: 0.036349 Accuracy 100.00%\n",
            "Epoch  530/1000 Cost: 0.035734 Accuracy 100.00%\n",
            "Epoch  540/1000 Cost: 0.035138 Accuracy 100.00%\n",
            "Epoch  550/1000 Cost: 0.034563 Accuracy 100.00%\n",
            "Epoch  560/1000 Cost: 0.034006 Accuracy 100.00%\n",
            "Epoch  570/1000 Cost: 0.033468 Accuracy 100.00%\n",
            "Epoch  580/1000 Cost: 0.032946 Accuracy 100.00%\n",
            "Epoch  590/1000 Cost: 0.032441 Accuracy 100.00%\n",
            "Epoch  600/1000 Cost: 0.031951 Accuracy 100.00%\n",
            "Epoch  610/1000 Cost: 0.031476 Accuracy 100.00%\n",
            "Epoch  620/1000 Cost: 0.031014 Accuracy 100.00%\n",
            "Epoch  630/1000 Cost: 0.030567 Accuracy 100.00%\n",
            "Epoch  640/1000 Cost: 0.030132 Accuracy 100.00%\n",
            "Epoch  650/1000 Cost: 0.029710 Accuracy 100.00%\n",
            "Epoch  660/1000 Cost: 0.029299 Accuracy 100.00%\n",
            "Epoch  670/1000 Cost: 0.028900 Accuracy 100.00%\n",
            "Epoch  680/1000 Cost: 0.028512 Accuracy 100.00%\n",
            "Epoch  690/1000 Cost: 0.028134 Accuracy 100.00%\n",
            "Epoch  700/1000 Cost: 0.027766 Accuracy 100.00%\n",
            "Epoch  710/1000 Cost: 0.027407 Accuracy 100.00%\n",
            "Epoch  720/1000 Cost: 0.027058 Accuracy 100.00%\n",
            "Epoch  730/1000 Cost: 0.026718 Accuracy 100.00%\n",
            "Epoch  740/1000 Cost: 0.026386 Accuracy 100.00%\n",
            "Epoch  750/1000 Cost: 0.026063 Accuracy 100.00%\n",
            "Epoch  760/1000 Cost: 0.025747 Accuracy 100.00%\n",
            "Epoch  770/1000 Cost: 0.025439 Accuracy 100.00%\n",
            "Epoch  780/1000 Cost: 0.025138 Accuracy 100.00%\n",
            "Epoch  790/1000 Cost: 0.024845 Accuracy 100.00%\n",
            "Epoch  800/1000 Cost: 0.024558 Accuracy 100.00%\n",
            "Epoch  810/1000 Cost: 0.024278 Accuracy 100.00%\n",
            "Epoch  820/1000 Cost: 0.024004 Accuracy 100.00%\n",
            "Epoch  830/1000 Cost: 0.023737 Accuracy 100.00%\n",
            "Epoch  840/1000 Cost: 0.023475 Accuracy 100.00%\n",
            "Epoch  850/1000 Cost: 0.023219 Accuracy 100.00%\n",
            "Epoch  860/1000 Cost: 0.022969 Accuracy 100.00%\n",
            "Epoch  870/1000 Cost: 0.022724 Accuracy 100.00%\n",
            "Epoch  880/1000 Cost: 0.022484 Accuracy 100.00%\n",
            "Epoch  890/1000 Cost: 0.022250 Accuracy 100.00%\n",
            "Epoch  900/1000 Cost: 0.022020 Accuracy 100.00%\n",
            "Epoch  910/1000 Cost: 0.021795 Accuracy 100.00%\n",
            "Epoch  920/1000 Cost: 0.021574 Accuracy 100.00%\n",
            "Epoch  930/1000 Cost: 0.021358 Accuracy 100.00%\n",
            "Epoch  940/1000 Cost: 0.021147 Accuracy 100.00%\n",
            "Epoch  950/1000 Cost: 0.020939 Accuracy 100.00%\n",
            "Epoch  960/1000 Cost: 0.020736 Accuracy 100.00%\n",
            "Epoch  970/1000 Cost: 0.020536 Accuracy 100.00%\n",
            "Epoch  980/1000 Cost: 0.020340 Accuracy 100.00%\n",
            "Epoch  990/1000 Cost: 0.020148 Accuracy 100.00%\n",
            "Epoch 1000/1000 Cost: 0.019960 Accuracy 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "riVNCDfjG5To"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}