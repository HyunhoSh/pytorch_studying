{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_linear_regression.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Regression"
      ],
      "metadata": {
        "id": "hOw5z_sTnZQE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhFUPxt9m7UE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "# 현재 실습하고 있는 파이썬 코드를 재실행해도 다음에도 같은 결과가 나오도록 random seed\n",
        "torch.manual_seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train  = torch.FloatTensor([[1],[2],[3]])\n",
        "y_train = torch.FloatTensor([[2],[4],[6]])"
      ],
      "metadata": {
        "id": "Fuow_uWenRd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "id": "JjHh2wHtnoSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 가중치 0으로 초기화\n",
        "# 학습을 통해 값이 변경되는 변수임을 명시 -> requires_grad=True\n",
        "W = torch.zeros(1,requires_grad=True)\n",
        "\n",
        "print(W)"
      ],
      "metadata": {
        "id": "wap1wEf4nqoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# b도 초기화\n",
        "b = torch.zeros(1,requires_grad=True)\n",
        "print(b)"
      ],
      "metadata": {
        "id": "8bsUtw25oGFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 선형회귀 공식 가설 세우기 f = wx +b\n",
        "hypothesis = x_train*W + b\n",
        "print(hypothesis)"
      ],
      "metadata": {
        "id": "FngP13HuoNGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cost function\n",
        "cost = torch.mean((hypothesis-y_train)**2)\n",
        "print(cost)"
      ],
      "metadata": {
        "id": "3pAh5nu1oofo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradient descent 구현\n",
        "optimizer = optim.SGD([W,b],lr=0.02)"
      ],
      "metadata": {
        "id": "ESdi1IVdoxiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gradient 0으로 초기화\n",
        "optimizer.zero_grad()\n",
        "# cost function 미분해서 graident 계산\n",
        "cost.backward()\n",
        "# W,b 업뎃\n",
        "optimizer.step()"
      ],
      "metadata": {
        "id": "T5LQmZuJo5WG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = torch.FloatTensor([[1], [2], [3]])\n",
        "y_train = torch.FloatTensor([[2], [4], [6]])\n",
        "\n",
        "W = torch.zeros(1, requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "\n",
        "\n",
        "# 원하는만큼 gd 반복\n",
        "nb_epochs=2000\n",
        "\n",
        "optimizer = optim.SGD([W,b],lr=0.02)\n",
        "\n",
        "for epoch in range(nb_epochs):\n",
        "  hypothesis = x_train*W+b\n",
        "\n",
        "  cost = torch.mean((hypothesis-y_train)**2)\n",
        "\n",
        "  # gradient 0으로 초기화\n",
        "  optimizer.zero_grad()\n",
        "  # cost function 미분해서 graident 계산\n",
        "  cost.backward()\n",
        "  # W,b 업뎃\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch%100 ==0:\n",
        "    print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(\n",
        "            epoch, nb_epochs, W.item(), b.item(), cost.item()\n",
        "        ))"
      ],
      "metadata": {
        "id": "yBH5L6O-pE_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 파이토치는 미분을 통해 얻은 기울기를 이전에 계산된 기울기 값에 누적시키는 특징이 있기 때문에, optimizer.zero_grad()를 통해 미분값을 0으로 계속 초기화 시켜줘야한다.\n",
        "\n",
        "## 2. torch.manual_seed()를 사용하면 다른 컴퓨터에서 실행시켜도 동일한 결과를 얻을 수 있는데, 그 이유는 torch.manual_seed()는 난수발생 순서와 값을 동일하게 보장해주기 때문이다.\n",
        "\n",
        "## 3. 텐서에는 requires_grad라는 속성이 있다. 이것을 True로 설정하면 자동 미분 기능이 적용되고, 어떤 복잡한 구조던 파라미터들에 모두 이 기능이 적용된다. 이렇게 연산하면 계산 그래프가 생성되고 backward 함수를 호출하면 그래프로부터 자동으로 미분이 계산된다."
      ],
      "metadata": {
        "id": "ot_-KqFHqQXw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 자동 미분 기능 -> Autograd"
      ],
      "metadata": {
        "id": "kLtacvA2rl1K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = torch.tensor(2.0,requires_grad=True)"
      ],
      "metadata": {
        "id": "i9OscOw4pzSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = w**2\n",
        "z = 2*y+5\n",
        "\n",
        "z.backward() #  backward로 해당 수식의 w에 대한 기울기 계산"
      ],
      "metadata": {
        "id": "Sd4fbzyfrssL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Derivative of W:{}\".format(w.grad))"
      ],
      "metadata": {
        "id": "ZfJx20ETr0-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 다중 선형 회귀 (Multivariable Linear Regression)"
      ],
      "metadata": {
        "id": "ffRSMwARsAe0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 독립변수 3개와 종속변수 1개\n",
        "# H(x) = w1x1 + w2x2 + w3x3 +b\n",
        "\n",
        "x1_train = torch.FloatTensor([[73], [93], [89], [96], [73]])\n",
        "x2_train = torch.FloatTensor([[80], [88], [91], [98], [66]])\n",
        "x3_train = torch.FloatTensor([[75], [93], [90], [100], [70]])\n",
        "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
        "\n",
        "# 가중치도 3개 선언!\n",
        "w1 = torch.zeros(1,requires_grad=True)\n",
        "w2 = torch.zeros(1,requires_grad=True)\n",
        "w3 = torch.zeros(1,requires_grad=True)\n",
        "\n",
        "b = torch.zeros(1,requires_grad=True)"
      ],
      "metadata": {
        "id": "Q2aG3lWPr6i4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD([w1,w2,w3,b],lr = 1e-5)\n",
        "\n",
        "nb =epochs= 1000\n",
        "\n",
        "for epoch in range(nb_epochs+1):\n",
        "  hypothesis = x1_train*w1 + x2_train*w2 + x3_train*w3 + b # matmul로 가능\n",
        "\n",
        "  cost = torch.mean((hypothesis-y_train)**2)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "        print('Epoch {:4d}/{} w1: {:.3f} w2: {:.3f} w3: {:.3f} b: {:.3f} Cost: {:.6f}'.format(\n",
        "            epoch, nb_epochs, w1.item(), w2.item(), w3.item(), b.item(), cost.item()\n",
        "        ))"
      ],
      "metadata": {
        "id": "3bL8v8s-vNgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train  =  torch.FloatTensor([[73,  80,  75], \n",
        "                               [93,  88,  93], \n",
        "                               [89,  91,  80], \n",
        "                               [96,  98,  100],   \n",
        "                               [73,  66,  70]])  # 5x3 형태 \n",
        "y_train  =  torch.FloatTensor([[152],  [185],  [180],  [196],  [142]])\n",
        "\n",
        "# 가중치도 3개 선언!\n",
        "# w1 = torch.zeros(1,requires_grad=True)\n",
        "# w2 = torch.zeros(1,requires_grad=True)\n",
        "# w3 = torch.zeros(1,requires_grad=True)\n",
        "W = torch.zeros((3,1),requires_grad=True) # 3x1 형태\n",
        "\n",
        "b = torch.zeros(1,requires_grad=True)\n",
        "\n",
        "optimizer = optim.SGD([W,b],lr = 1e-5)\n",
        "\n",
        "nb =epochs= 20\n",
        "\n",
        "for epoch in range(nb_epochs+1):\n",
        "  # hypothesis = x1_train*w1 + x2_train*w2 + x3_train*w3 + b # matmul로 가능\n",
        "  hypothesis = x_train.matmul(W) + b\n",
        "\n",
        "  cost = torch.mean((hypothesis-y_train)**2)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "        print('Epoch {:4d}/{} hypothesis: {} Cost: {:.6f}'.format(\n",
        "            epoch, nb_epochs, hypothesis.squeeze().detach(), cost.item()\n",
        "        ))"
      ],
      "metadata": {
        "id": "RS_lzvZQv7kg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FLgxBxtMwqfS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}