{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_linear_regression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Regression"
      ],
      "metadata": {
        "id": "hOw5z_sTnZQE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PhFUPxt9m7UE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cc822bb-cbd8-4131-9c40-c545cc947f8d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fa144372150>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "# 현재 실습하고 있는 파이썬 코드를 재실행해도 다음에도 같은 결과가 나오도록 random seed\n",
        "torch.manual_seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train  = torch.FloatTensor([[1],[2],[3]])\n",
        "y_train = torch.FloatTensor([[2],[4],[6]])"
      ],
      "metadata": {
        "id": "Fuow_uWenRd7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "id": "JjHh2wHtnoSJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98f61622-8317-4a02-c4a7-78e1378e1cf9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 1])\n",
            "torch.Size([3, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 가중치 0으로 초기화\n",
        "# 학습을 통해 값이 변경되는 변수임을 명시 -> requires_grad=True\n",
        "W = torch.zeros(1,requires_grad=True)\n",
        "\n",
        "print(W)"
      ],
      "metadata": {
        "id": "wap1wEf4nqoZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6032783b-4e6b-4b93-81bc-4849649dc241"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# b도 초기화\n",
        "b = torch.zeros(1,requires_grad=True)\n",
        "print(b)"
      ],
      "metadata": {
        "id": "8bsUtw25oGFF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99c30f44-daf3-44e8-818e-009ecc6c9475"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 선형회귀 공식 가설 세우기 f = wx +b\n",
        "hypothesis = x_train*W + b\n",
        "print(hypothesis)"
      ],
      "metadata": {
        "id": "FngP13HuoNGe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94c78035-4216-457c-de6c-e307e87caa45"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.],\n",
            "        [0.],\n",
            "        [0.]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cost function\n",
        "cost = torch.mean((hypothesis-y_train)**2)\n",
        "print(cost)"
      ],
      "metadata": {
        "id": "3pAh5nu1oofo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "267f61be-6120-42d5-8759-6b35552ff966"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(18.6667, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradient descent 구현\n",
        "optimizer = optim.SGD([W,b],lr=0.02)"
      ],
      "metadata": {
        "id": "ESdi1IVdoxiH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gradient 0으로 초기화\n",
        "optimizer.zero_grad()\n",
        "# cost function 미분해서 graident 계산\n",
        "cost.backward()\n",
        "# W,b 업뎃\n",
        "optimizer.step()"
      ],
      "metadata": {
        "id": "T5LQmZuJo5WG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = torch.FloatTensor([[1], [2], [3]])\n",
        "y_train = torch.FloatTensor([[2], [4], [6]])\n",
        "\n",
        "W = torch.zeros(1, requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "\n",
        "\n",
        "# 원하는만큼 gd 반복\n",
        "nb_epochs=2000\n",
        "\n",
        "optimizer = optim.SGD([W,b],lr=0.02)\n",
        "\n",
        "for epoch in range(nb_epochs):\n",
        "  hypothesis = x_train*W+b\n",
        "\n",
        "  cost = torch.mean((hypothesis-y_train)**2)\n",
        "\n",
        "  # gradient 0으로 초기화\n",
        "  optimizer.zero_grad()\n",
        "  # cost function 미분해서 graident 계산\n",
        "  cost.backward()\n",
        "  # W,b 업뎃\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch%100 ==0:\n",
        "    print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(\n",
        "            epoch, nb_epochs, W.item(), b.item(), cost.item()\n",
        "        ))"
      ],
      "metadata": {
        "id": "yBH5L6O-pE_7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77cbe9cb-5794-4c4e-840f-da2ea8fd2a12"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/2000 W: 0.373, b: 0.160 Cost: 18.666666\n",
            "Epoch  100/2000 W: 1.801, b: 0.453 Cost: 0.029732\n",
            "Epoch  200/2000 W: 1.877, b: 0.280 Cost: 0.011340\n",
            "Epoch  300/2000 W: 1.924, b: 0.173 Cost: 0.004325\n",
            "Epoch  400/2000 W: 1.953, b: 0.107 Cost: 0.001650\n",
            "Epoch  500/2000 W: 1.971, b: 0.066 Cost: 0.000629\n",
            "Epoch  600/2000 W: 1.982, b: 0.041 Cost: 0.000240\n",
            "Epoch  700/2000 W: 1.989, b: 0.025 Cost: 0.000092\n",
            "Epoch  800/2000 W: 1.993, b: 0.016 Cost: 0.000035\n",
            "Epoch  900/2000 W: 1.996, b: 0.010 Cost: 0.000013\n",
            "Epoch 1000/2000 W: 1.997, b: 0.006 Cost: 0.000005\n",
            "Epoch 1100/2000 W: 1.998, b: 0.004 Cost: 0.000002\n",
            "Epoch 1200/2000 W: 1.999, b: 0.002 Cost: 0.000001\n",
            "Epoch 1300/2000 W: 1.999, b: 0.001 Cost: 0.000000\n",
            "Epoch 1400/2000 W: 2.000, b: 0.001 Cost: 0.000000\n",
            "Epoch 1500/2000 W: 2.000, b: 0.001 Cost: 0.000000\n",
            "Epoch 1600/2000 W: 2.000, b: 0.000 Cost: 0.000000\n",
            "Epoch 1700/2000 W: 2.000, b: 0.000 Cost: 0.000000\n",
            "Epoch 1800/2000 W: 2.000, b: 0.000 Cost: 0.000000\n",
            "Epoch 1900/2000 W: 2.000, b: 0.000 Cost: 0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 파이토치는 미분을 통해 얻은 기울기를 이전에 계산된 기울기 값에 누적시키는 특징이 있기 때문에, optimizer.zero_grad()를 통해 미분값을 0으로 계속 초기화 시켜줘야한다.\n",
        "\n",
        "## 2. torch.manual_seed()를 사용하면 다른 컴퓨터에서 실행시켜도 동일한 결과를 얻을 수 있는데, 그 이유는 torch.manual_seed()는 난수발생 순서와 값을 동일하게 보장해주기 때문이다.\n",
        "\n",
        "## 3. 텐서에는 requires_grad라는 속성이 있다. 이것을 True로 설정하면 자동 미분 기능이 적용되고, 어떤 복잡한 구조던 파라미터들에 모두 이 기능이 적용된다. 이렇게 연산하면 계산 그래프가 생성되고 backward 함수를 호출하면 그래프로부터 자동으로 미분이 계산된다."
      ],
      "metadata": {
        "id": "ot_-KqFHqQXw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 자동 미분 기능 -> Autograd"
      ],
      "metadata": {
        "id": "kLtacvA2rl1K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = torch.tensor(2.0,requires_grad=True)"
      ],
      "metadata": {
        "id": "i9OscOw4pzSo"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = w**2\n",
        "z = 2*y+5\n",
        "\n",
        "z.backward() #  backward로 해당 수식의 w에 대한 기울기 계산"
      ],
      "metadata": {
        "id": "Sd4fbzyfrssL"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Derivative of W:{}\".format(w.grad))"
      ],
      "metadata": {
        "id": "ZfJx20ETr0-F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca077dd2-8d7e-4141-af49-feee51bb0312"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Derivative of W:8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 다중 선형 회귀 (Multivariable Linear Regression)"
      ],
      "metadata": {
        "id": "ffRSMwARsAe0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 독립변수 3개와 종속변수 1개\n",
        "# H(x) = w1x1 + w2x2 + w3x3 +b\n",
        "\n",
        "x1_train = torch.FloatTensor([[73], [93], [89], [96], [73]])\n",
        "x2_train = torch.FloatTensor([[80], [88], [91], [98], [66]])\n",
        "x3_train = torch.FloatTensor([[75], [93], [90], [100], [70]])\n",
        "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
        "\n",
        "# 가중치도 3개 선언!\n",
        "w1 = torch.zeros(1,requires_grad=True)\n",
        "w2 = torch.zeros(1,requires_grad=True)\n",
        "w3 = torch.zeros(1,requires_grad=True)\n",
        "\n",
        "b = torch.zeros(1,requires_grad=True)"
      ],
      "metadata": {
        "id": "Q2aG3lWPr6i4"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD([w1,w2,w3,b],lr = 1e-5)\n",
        "\n",
        "nb =epochs= 1000\n",
        "\n",
        "for epoch in range(nb_epochs+1):\n",
        "  hypothesis = x1_train*w1 + x2_train*w2 + x3_train*w3 + b # matmul로 가능\n",
        "\n",
        "  cost = torch.mean((hypothesis-y_train)**2)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "        print('Epoch {:4d}/{} w1: {:.3f} w2: {:.3f} w3: {:.3f} b: {:.3f} Cost: {:.6f}'.format(\n",
        "            epoch, nb_epochs, w1.item(), w2.item(), w3.item(), b.item(), cost.item()\n",
        "        ))"
      ],
      "metadata": {
        "id": "3bL8v8s-vNgO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a08b399-b817-49fb-8fb5-886d61f4b5fa"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/2000 w1: 0.294 w2: 0.294 w3: 0.297 b: 0.003 Cost: 29661.800781\n",
            "Epoch  100/2000 w1: 0.674 w2: 0.661 w3: 0.676 b: 0.008 Cost: 1.563628\n",
            "Epoch  200/2000 w1: 0.679 w2: 0.655 w3: 0.677 b: 0.008 Cost: 1.497595\n",
            "Epoch  300/2000 w1: 0.684 w2: 0.649 w3: 0.677 b: 0.008 Cost: 1.435044\n",
            "Epoch  400/2000 w1: 0.689 w2: 0.643 w3: 0.678 b: 0.008 Cost: 1.375726\n",
            "Epoch  500/2000 w1: 0.694 w2: 0.638 w3: 0.678 b: 0.009 Cost: 1.319507\n",
            "Epoch  600/2000 w1: 0.699 w2: 0.633 w3: 0.679 b: 0.009 Cost: 1.266222\n",
            "Epoch  700/2000 w1: 0.704 w2: 0.627 w3: 0.679 b: 0.009 Cost: 1.215703\n",
            "Epoch  800/2000 w1: 0.709 w2: 0.622 w3: 0.679 b: 0.009 Cost: 1.167810\n",
            "Epoch  900/2000 w1: 0.713 w2: 0.617 w3: 0.680 b: 0.009 Cost: 1.122429\n",
            "Epoch 1000/2000 w1: 0.718 w2: 0.613 w3: 0.680 b: 0.009 Cost: 1.079390\n",
            "Epoch 1100/2000 w1: 0.722 w2: 0.608 w3: 0.680 b: 0.009 Cost: 1.038574\n",
            "Epoch 1200/2000 w1: 0.727 w2: 0.603 w3: 0.681 b: 0.010 Cost: 0.999884\n",
            "Epoch 1300/2000 w1: 0.731 w2: 0.599 w3: 0.681 b: 0.010 Cost: 0.963217\n",
            "Epoch 1400/2000 w1: 0.735 w2: 0.595 w3: 0.681 b: 0.010 Cost: 0.928427\n",
            "Epoch 1500/2000 w1: 0.739 w2: 0.591 w3: 0.681 b: 0.010 Cost: 0.895448\n",
            "Epoch 1600/2000 w1: 0.743 w2: 0.586 w3: 0.682 b: 0.010 Cost: 0.864169\n",
            "Epoch 1700/2000 w1: 0.746 w2: 0.583 w3: 0.682 b: 0.010 Cost: 0.834509\n",
            "Epoch 1800/2000 w1: 0.750 w2: 0.579 w3: 0.682 b: 0.010 Cost: 0.806380\n",
            "Epoch 1900/2000 w1: 0.754 w2: 0.575 w3: 0.682 b: 0.010 Cost: 0.779696\n",
            "Epoch 2000/2000 w1: 0.757 w2: 0.571 w3: 0.682 b: 0.011 Cost: 0.754379\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train  =  torch.FloatTensor([[73,  80,  75], \n",
        "                               [93,  88,  93], \n",
        "                               [89,  91,  80], \n",
        "                               [96,  98,  100],   \n",
        "                               [73,  66,  70]])  # 5x3 형태 \n",
        "y_train  =  torch.FloatTensor([[152],  [185],  [180],  [196],  [142]])\n",
        "\n",
        "# 가중치도 3개 선언!\n",
        "# w1 = torch.zeros(1,requires_grad=True)\n",
        "# w2 = torch.zeros(1,requires_grad=True)\n",
        "# w3 = torch.zeros(1,requires_grad=True)\n",
        "W = torch.zeros((3,1),requires_grad=True) # 3x1 형태\n",
        "\n",
        "b = torch.zeros(1,requires_grad=True)\n",
        "\n",
        "optimizer = optim.SGD([W,b],lr = 1e-5)\n",
        "\n",
        "nb =epochs= 20\n",
        "\n",
        "for epoch in range(nb_epochs+1):\n",
        "  # hypothesis = x1_train*w1 + x2_train*w2 + x3_train*w3 + b # matmul로 가능\n",
        "  hypothesis = x_train.matmul(W) + b\n",
        "\n",
        "  cost = torch.mean((hypothesis-y_train)**2)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "        print('Epoch {:4d}/{} hypothesis: {} Cost: {:.6f}'.format(\n",
        "            epoch, nb_epochs, hypothesis.squeeze().detach(), cost.item()\n",
        "        ))"
      ],
      "metadata": {
        "id": "RS_lzvZQv7kg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dae9b2a7-9008-4039-8dce-7ed9067d3c8b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/2000 hypothesis: tensor([0., 0., 0., 0., 0.]) Cost: 29661.800781\n",
            "Epoch  100/2000 hypothesis: tensor([154.0433, 185.0925, 175.8312, 198.5701, 141.2221]) Cost: 5.754573\n",
            "Epoch  200/2000 hypothesis: tensor([154.0278, 185.0649, 175.9335, 198.5128, 141.2284]) Cost: 5.512386\n",
            "Epoch  300/2000 hypothesis: tensor([154.0120, 185.0385, 176.0329, 198.4569, 141.2353]) Cost: 5.281667\n",
            "Epoch  400/2000 hypothesis: tensor([153.9960, 185.0133, 176.1295, 198.4022, 141.2426]) Cost: 5.061907\n",
            "Epoch  500/2000 hypothesis: tensor([153.9797, 184.9892, 176.2233, 198.3488, 141.2504]) Cost: 4.852424\n",
            "Epoch  600/2000 hypothesis: tensor([153.9632, 184.9662, 176.3143, 198.2966, 141.2586]) Cost: 4.652731\n",
            "Epoch  700/2000 hypothesis: tensor([153.9465, 184.9442, 176.4029, 198.2456, 141.2672]) Cost: 4.462265\n",
            "Epoch  800/2000 hypothesis: tensor([153.9296, 184.9232, 176.4888, 198.1958, 141.2762]) Cost: 4.280604\n",
            "Epoch  900/2000 hypothesis: tensor([153.9126, 184.9032, 176.5724, 198.1471, 141.2855]) Cost: 4.107261\n",
            "Epoch 1000/2000 hypothesis: tensor([153.8955, 184.8841, 176.6536, 198.0995, 141.2951]) Cost: 3.941853\n",
            "Epoch 1100/2000 hypothesis: tensor([153.8782, 184.8659, 176.7325, 198.0529, 141.3051]) Cost: 3.783899\n",
            "Epoch 1200/2000 hypothesis: tensor([153.8608, 184.8486, 176.8092, 198.0075, 141.3153]) Cost: 3.633053\n",
            "Epoch 1300/2000 hypothesis: tensor([153.8434, 184.8320, 176.8838, 197.9630, 141.3257]) Cost: 3.488978\n",
            "Epoch 1400/2000 hypothesis: tensor([153.8259, 184.8163, 176.9563, 197.9195, 141.3364]) Cost: 3.351316\n",
            "Epoch 1500/2000 hypothesis: tensor([153.8083, 184.8013, 177.0268, 197.8770, 141.3473]) Cost: 3.219726\n",
            "Epoch 1600/2000 hypothesis: tensor([153.7908, 184.7870, 177.0953, 197.8355, 141.3584]) Cost: 3.093974\n",
            "Epoch 1700/2000 hypothesis: tensor([153.7732, 184.7734, 177.1620, 197.7948, 141.3697]) Cost: 2.973701\n",
            "Epoch 1800/2000 hypothesis: tensor([153.7556, 184.7604, 177.2268, 197.7551, 141.3811]) Cost: 2.858673\n",
            "Epoch 1900/2000 hypothesis: tensor([153.7380, 184.7481, 177.2898, 197.7162, 141.3927]) Cost: 2.748659\n",
            "Epoch 2000/2000 hypothesis: tensor([153.7204, 184.7364, 177.3512, 197.6782, 141.4043]) Cost: 2.643340\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# nn.Module로 구현"
      ],
      "metadata": {
        "id": "F56CTO_MsiTw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as f\n",
        "\n",
        "torch.manual_seed(1)"
      ],
      "metadata": {
        "id": "FLgxBxtMwqfS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca6b6777-1613-4183-d85b-634f76ef574b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fa144372150>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# y=2x 를 가정된 상태에서 만들어진 데이터\n",
        "x_train = torch.FloatTensor([[1], [2], [3]])\n",
        "y_train = torch.FloatTensor([[2], [4], [6]])\n",
        "\n",
        "# 단순 선형 회귀이므로 input_dim=1, output_dim = 1\n",
        "model = nn.Linear(1,1)\n",
        "\n",
        "print(list(model.parameters())) # 모델의 W,b를 출력"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JG-NEGu6st9I",
        "outputId": "548e5610-e730-4c37-cb76-ebfb24be3400"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Parameter containing:\n",
            "tensor([[0.5153]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.4414], requires_grad=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer 설정\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "Pst0nW90tPd6"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_epochs = 2000\n",
        "\n",
        "for epoch in range(nb_epochs+1):\n",
        "  prediction = model(x_train)\n",
        "\n",
        "  cost = F.mse_loss(prediction,y_train) # pytorch에 내장되어있는 mse\n",
        "\n",
        "  # cost로 prediction 개선\n",
        "  # gradient를 0으로 초기화\n",
        "  optimizer.zero_grad()\n",
        "  # cost함수 미분으로 gradient 게산\n",
        "  cost.backward() # backward 연산 -> 학습과정에서 cost function을 미분하여 기울기 구하는것\n",
        "  # W,b 업뎃\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch%100==0:\n",
        "    print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
        "          epoch, nb_epochs, cost.item()\n",
        "      ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1Y9jk2utbk0",
        "outputId": "5bd31105-479b-485c-96b2-c496e3e45670"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/2000 Cost: 13.103541\n",
            "Epoch  100/2000 Cost: 0.002791\n",
            "Epoch  200/2000 Cost: 0.001724\n",
            "Epoch  300/2000 Cost: 0.001066\n",
            "Epoch  400/2000 Cost: 0.000658\n",
            "Epoch  500/2000 Cost: 0.000407\n",
            "Epoch  600/2000 Cost: 0.000251\n",
            "Epoch  700/2000 Cost: 0.000155\n",
            "Epoch  800/2000 Cost: 0.000096\n",
            "Epoch  900/2000 Cost: 0.000059\n",
            "Epoch 1000/2000 Cost: 0.000037\n",
            "Epoch 1100/2000 Cost: 0.000023\n",
            "Epoch 1200/2000 Cost: 0.000014\n",
            "Epoch 1300/2000 Cost: 0.000009\n",
            "Epoch 1400/2000 Cost: 0.000005\n",
            "Epoch 1500/2000 Cost: 0.000003\n",
            "Epoch 1600/2000 Cost: 0.000002\n",
            "Epoch 1700/2000 Cost: 0.000001\n",
            "Epoch 1800/2000 Cost: 0.000001\n",
            "Epoch 1900/2000 Cost: 0.000000\n",
            "Epoch 2000/2000 Cost: 0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# x에 임의의 값 넣어서 예측값 도출\n",
        "new_var = torch.FloatTensor([4.0])\n",
        "\n",
        "pred_y = model(new_var) # forward 연산\n",
        "print(\"Prediction of model when input = 4: {}\".format(pred_y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mMFzDTRt8g0",
        "outputId": "9f852e35-be45-4ff8-cb8b-720c4ae8e014"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction of model when input = 4: tensor([7.9989], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(model.parameters()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_audo9wvBax",
        "outputId": "27539452-4d76-44b3-a7a9-7d681da98f9b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Parameter containing:\n",
            "tensor([[1.9994]], requires_grad=True), Parameter containing:\n",
            "tensor([0.0014], requires_grad=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multivaritive linear regression by using nn"
      ],
      "metadata": {
        "id": "1ElMqol3vUhH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as f\n",
        "\n",
        "torch.manual_seed(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrB7ozC9vJ8K",
        "outputId": "6f371fe6-ddda-4144-aef3-bbdea42df6a9"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fa144372150>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# H(x) = w1x1 + w2x2 + w3x3 + b\n",
        "x_train = torch.FloatTensor([[73, 80, 75],\n",
        "                             [93, 88, 93],\n",
        "                             [89, 91, 90],\n",
        "                             [96, 98, 100],\n",
        "                             [73, 66, 70]])\n",
        "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
        "\n",
        "# 독립변수가 3개이므로, input_dim = 3, output_dim은 종속변수가 1개이므로 1\n",
        "model = nn.Linear(3,1)"
      ],
      "metadata": {
        "id": "5i2NSOC6veqQ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(model.parameters()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umd3lrobwRmP",
        "outputId": "381d01c2-dd81-4589-c1e3-74da69b70141"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Parameter containing:\n",
            "tensor([[ 0.2975, -0.2548, -0.1119]], requires_grad=True), Parameter containing:\n",
            "tensor([0.2710], requires_grad=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(),lr = 1e-5)\n",
        "\n",
        "nb_epochs = 2000\n",
        "\n",
        "for epoch in range(nb_epochs+1):\n",
        "  prediction = model(x_train)\n",
        "\n",
        "  cost = F.mse_loss(prediction,y_train)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch%100==0:\n",
        "    print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
        "          epoch, nb_epochs, cost.item()\n",
        "      ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikGRLbImwfjo",
        "outputId": "60e1385a-87fe-49be-eda4-63afa71bbd79"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/2000 Cost: 31667.597656\n",
            "Epoch  100/2000 Cost: 0.225993\n",
            "Epoch  200/2000 Cost: 0.223911\n",
            "Epoch  300/2000 Cost: 0.221941\n",
            "Epoch  400/2000 Cost: 0.220059\n",
            "Epoch  500/2000 Cost: 0.218271\n",
            "Epoch  600/2000 Cost: 0.216575\n",
            "Epoch  700/2000 Cost: 0.214950\n",
            "Epoch  800/2000 Cost: 0.213413\n",
            "Epoch  900/2000 Cost: 0.211952\n",
            "Epoch 1000/2000 Cost: 0.210560\n",
            "Epoch 1100/2000 Cost: 0.209232\n",
            "Epoch 1200/2000 Cost: 0.207967\n",
            "Epoch 1300/2000 Cost: 0.206761\n",
            "Epoch 1400/2000 Cost: 0.205619\n",
            "Epoch 1500/2000 Cost: 0.204522\n",
            "Epoch 1600/2000 Cost: 0.203484\n",
            "Epoch 1700/2000 Cost: 0.202485\n",
            "Epoch 1800/2000 Cost: 0.201542\n",
            "Epoch 1900/2000 Cost: 0.200635\n",
            "Epoch 2000/2000 Cost: 0.199769\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력값 [73,80,75]에 대한 예측값 도출\n",
        "\n",
        "new_var = torch.FloatTensor([[73,80,75]])\n",
        "pred_y = model(new_var)\n",
        "print(\"prediction of model when input is [73,80,75]:{}\".format(pred_y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vmqj87_OxgYI",
        "outputId": "07121457-9641-4704-d0db-69fdd96d7f41"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prediction of model when input is [73,80,75]:tensor([[151.2305]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(model.parameters()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMLqW4WOx1WQ",
        "outputId": "4df20ce0-658e-4810-afe3-a08bfacf8cfd"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Parameter containing:\n",
            "tensor([[0.9778, 0.4539, 0.5768]], requires_grad=True), Parameter containing:\n",
            "tensor([0.2802], requires_grad=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using class"
      ],
      "metadata": {
        "id": "jRdFk7zTyjob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.nn.Module을 상속받는 파이썬 클래스\n",
        "class LinearRegressionModel(nn.Module):\n",
        "  def __init__(self): # 생성자 정의\n",
        "    super().__init__() # super()를 통해 여기서 만든 클래스는 nn.Module 클래스의\n",
        "    # 속성들을 가지고 초기화됨\n",
        "    self.linear = nn.Linear(1,1) \n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.linear(x)\n",
        "\n",
        "model = LinearRegressionModel()\n",
        "\n",
        "# forward 함수는 model 객체를 데이터와 함께 호출하면 자동으로 수행이 된다."
      ],
      "metadata": {
        "id": "6Svy5vMPyh4X"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultivariateLinearRegressionModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(3,1)\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.linear(x)\n",
        "model = MultivariateLinearRegressionModel()"
      ],
      "metadata": {
        "id": "Uu1PHl2yzAHb"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "torch.manual_seed(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68IOVxPeznZf",
        "outputId": "10289476-9dfb-49ee-eb2e-d1f75c5f3c37"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fa144372150>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = torch.FloatTensor([[1], [2], [3]])\n",
        "y_train = torch.FloatTensor([[2], [4], [6]])"
      ],
      "metadata": {
        "id": "6lg3fsv2z6jB"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearRegressionModel(nn.Module):\n",
        "  def __init__(self): # 생성자 정의\n",
        "    super().__init__() # super()를 통해 여기서 만든 클래스는 nn.Module 클래스의\n",
        "    # 속성들을 가지고 초기화됨\n",
        "    self.linear = nn.Linear(1,1) \n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.linear(x)\n",
        "\n",
        "model = LinearRegressionModel()"
      ],
      "metadata": {
        "id": "ms7K3XXez7l4"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(),lr=0.01)"
      ],
      "metadata": {
        "id": "qA7UCHmbz9FK"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_epochs = 2000\n",
        "for epoch in range(nb_epochs+1):\n",
        "  prediction = model(x_train)\n",
        "\n",
        "  cost = F.mse_loss(prediction,y_train)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch%100==0:\n",
        "    print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
        "          epoch, nb_epochs, cost.item()\n",
        "      ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkOcvNbT0Cfr",
        "outputId": "8cf6836a-10ec-44de-8e4e-e0bf2ee8ac78"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/2000 Cost: 13.103541\n",
            "Epoch  100/2000 Cost: 0.002791\n",
            "Epoch  200/2000 Cost: 0.001724\n",
            "Epoch  300/2000 Cost: 0.001066\n",
            "Epoch  400/2000 Cost: 0.000658\n",
            "Epoch  500/2000 Cost: 0.000407\n",
            "Epoch  600/2000 Cost: 0.000251\n",
            "Epoch  700/2000 Cost: 0.000155\n",
            "Epoch  800/2000 Cost: 0.000096\n",
            "Epoch  900/2000 Cost: 0.000059\n",
            "Epoch 1000/2000 Cost: 0.000037\n",
            "Epoch 1100/2000 Cost: 0.000023\n",
            "Epoch 1200/2000 Cost: 0.000014\n",
            "Epoch 1300/2000 Cost: 0.000009\n",
            "Epoch 1400/2000 Cost: 0.000005\n",
            "Epoch 1500/2000 Cost: 0.000003\n",
            "Epoch 1600/2000 Cost: 0.000002\n",
            "Epoch 1700/2000 Cost: 0.000001\n",
            "Epoch 1800/2000 Cost: 0.000001\n",
            "Epoch 1900/2000 Cost: 0.000000\n",
            "Epoch 2000/2000 Cost: 0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 다중선형회귀\n",
        "x_train = torch.FloatTensor([[73, 80, 75],\n",
        "                             [93, 88, 93],\n",
        "                             [89, 91, 90],\n",
        "                             [96, 98, 100],\n",
        "                             [73, 66, 70]])\n",
        "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])"
      ],
      "metadata": {
        "id": "2z5NgECK0VqZ"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultivariateLinearRegressionModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(3,1)\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.linear(x)\n",
        "model = MultivariateLinearRegressionModel()"
      ],
      "metadata": {
        "id": "fJSrU9yy1Sdq"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5)\n",
        "\n",
        "nb_epochs=2000\n",
        "\n",
        "for epoch in range(nb_epochs+1):\n",
        "  prediction = model(x_train)\n",
        "\n",
        "  cost = F.mse_loss(prediction,y_train)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch%100==0:\n",
        "    print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
        "          epoch, nb_epochs, cost.item()\n",
        "      ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7RvXKJ71WW3",
        "outputId": "cd04f00c-4408-49b9-aa9d-68ed7f25ee38"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/2000 Cost: 42134.707031\n",
            "Epoch  100/2000 Cost: 5.960053\n",
            "Epoch  200/2000 Cost: 5.654707\n",
            "Epoch  300/2000 Cost: 5.365413\n",
            "Epoch  400/2000 Cost: 5.091429\n",
            "Epoch  500/2000 Cost: 4.831834\n",
            "Epoch  600/2000 Cost: 4.585997\n",
            "Epoch  700/2000 Cost: 4.353045\n",
            "Epoch  800/2000 Cost: 4.132426\n",
            "Epoch  900/2000 Cost: 3.923438\n",
            "Epoch 1000/2000 Cost: 3.725488\n",
            "Epoch 1100/2000 Cost: 3.537972\n",
            "Epoch 1200/2000 Cost: 3.360339\n",
            "Epoch 1300/2000 Cost: 3.192076\n",
            "Epoch 1400/2000 Cost: 3.032686\n",
            "Epoch 1500/2000 Cost: 2.881703\n",
            "Epoch 1600/2000 Cost: 2.738666\n",
            "Epoch 1700/2000 Cost: 2.603199\n",
            "Epoch 1800/2000 Cost: 2.474860\n",
            "Epoch 1900/2000 Cost: 2.353289\n",
            "Epoch 2000/2000 Cost: 2.238115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mini Batch and Data Load"
      ],
      "metadata": {
        "id": "1rsZvnvi2M_K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graident Descent를 사용했었지만, 데이터의 수가 엄청 많다면 전체 데이터에 대해 graident descent를 사용하는 것은 느린데다가 많은 계산량으로 메모리 초과가 발생할 수도 있다.\n",
        "## 따라서 전체 데이터를 더 작은 단위로 나누어서 해당 단위로 학습하는 개념이 나오게 되었는데, 이를 Mini Batch라 한다.\n",
        "\n",
        "## 전체 데이터를 미니 배치 단위로 나누게 되면, 미니 배치만큼만 가져가서 gradient descent를 수행하고 마지막 미니 배치까지 이를 반복한다. 전체 데이터에 대한 학습이 1회 끝나면, 1 epoch가 끝나는 형식이다.\n",
        "### epoch -> 전체 training data가 학습에 한번 사용된 주기\n",
        "\n",
        "## 미니 배치 학습에서는 미니 배치의 개수만큼 경사 하강법을 수행해야 전체 데이터가 한번 전부 사용되어 1 epoch가 됨. 미니 배치의 크기는 batch size라 한다.\n",
        "\n",
        "## batch size는 보통 2의 제곱수를 사용하는데, 그 이유는 CPU와 GPU의 메모리가 2의 배수이므로 배치 크기가 2의 제곱수일때 데이터 송수신의 효율을 높일 수 있기 때문이다."
      ],
      "metadata": {
        "id": "AfIpsagI2SA4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## iteration은 한번의 epoch 내에서 이루어지는 매개변수인 W,b의 업데이트 횟수이다. 전체 데이터가 2000개고, batch size를 200으로 한다면 iteration의 수는 10개다. 이는 한번의 epoch 당 매개변수 업데이트가 10번 이루어짐을 의미한다."
      ],
      "metadata": {
        "id": "3Cur7Cw84WSA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import TensorDataset # 텐서데이터셋\n",
        "from torch.utils.data import DataLoader # 데이터로더\n",
        "\n",
        "x_train = torch.FloatTensor([[73, 80, 75],\n",
        "                             [93, 88, 93],\n",
        "                             [89, 91, 90],\n",
        "                             [96, 98, 100],\n",
        "                             [73, 66, 70]])\n",
        "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
        "\n",
        "dataset = TensorDataset(x_train,y_train)\n",
        "# shuffle=True를 하게 되면 Epoch마다 데이터셋을 섞어서 데이터가 학습되는 순서를 바꾼다.\n",
        "# 모델이 데이터셋의 순서에 익숙해지지 않도록 순서를 섞게되면, 학습의 효율을\n",
        "# 보다 높일 수 있으므로 True를 주는 것을 권장 \n",
        "dataloader = DataLoader(dataset,batch_size=2, shuffle=True)"
      ],
      "metadata": {
        "id": "DjpBhLwr1qrx"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Linear(3,1)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5)\n",
        "\n",
        "nb_epochs=20\n",
        "\n",
        "for epoch in range(nb_epochs+1):\n",
        "  for batch_idx, samples in enumerate(dataloader):\n",
        "    x_train,y_train = samples\n",
        "\n",
        "    prediction = model(x_train)\n",
        "\n",
        "    cost = F.mse_loss(prediction,y_train)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print('Epoch {:4d}/{} Batch {}/{} Cost: {:.6f}'.format(\n",
        "        epoch, nb_epochs, batch_idx+1, len(dataloader),\n",
        "        cost.item()\n",
        "        ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyOhU3YN5hpj",
        "outputId": "34047e7f-d7a0-421a-fc7d-4bb1316ee894"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/20 Batch 1/3 Cost: 54524.218750\n",
            "Epoch    0/20 Batch 2/3 Cost: 8945.384766\n",
            "Epoch    0/20 Batch 3/3 Cost: 2403.548828\n",
            "Epoch    1/20 Batch 1/3 Cost: 1564.037354\n",
            "Epoch    1/20 Batch 2/3 Cost: 550.310242\n",
            "Epoch    1/20 Batch 3/3 Cost: 128.874252\n",
            "Epoch    2/20 Batch 1/3 Cost: 35.747013\n",
            "Epoch    2/20 Batch 2/3 Cost: 24.368774\n",
            "Epoch    2/20 Batch 3/3 Cost: 13.028359\n",
            "Epoch    3/20 Batch 1/3 Cost: 0.577810\n",
            "Epoch    3/20 Batch 2/3 Cost: 5.028281\n",
            "Epoch    3/20 Batch 3/3 Cost: 1.949444\n",
            "Epoch    4/20 Batch 1/3 Cost: 2.790044\n",
            "Epoch    4/20 Batch 2/3 Cost: 4.539840\n",
            "Epoch    4/20 Batch 3/3 Cost: 1.471585\n",
            "Epoch    5/20 Batch 1/3 Cost: 0.735286\n",
            "Epoch    5/20 Batch 2/3 Cost: 2.351912\n",
            "Epoch    5/20 Batch 3/3 Cost: 7.989922\n",
            "Epoch    6/20 Batch 1/3 Cost: 2.292079\n",
            "Epoch    6/20 Batch 2/3 Cost: 3.429396\n",
            "Epoch    6/20 Batch 3/3 Cost: 0.660007\n",
            "Epoch    7/20 Batch 1/3 Cost: 1.045065\n",
            "Epoch    7/20 Batch 2/3 Cost: 4.478187\n",
            "Epoch    7/20 Batch 3/3 Cost: 0.089189\n",
            "Epoch    8/20 Batch 1/3 Cost: 0.152515\n",
            "Epoch    8/20 Batch 2/3 Cost: 4.536362\n",
            "Epoch    8/20 Batch 3/3 Cost: 1.777520\n",
            "Epoch    9/20 Batch 1/3 Cost: 2.310009\n",
            "Epoch    9/20 Batch 2/3 Cost: 4.838376\n",
            "Epoch    9/20 Batch 3/3 Cost: 0.447284\n",
            "Epoch   10/20 Batch 1/3 Cost: 1.091354\n",
            "Epoch   10/20 Batch 2/3 Cost: 6.368413\n",
            "Epoch   10/20 Batch 3/3 Cost: 0.283590\n",
            "Epoch   11/20 Batch 1/3 Cost: 3.047707\n",
            "Epoch   11/20 Batch 2/3 Cost: 2.587975\n",
            "Epoch   11/20 Batch 3/3 Cost: 0.074560\n",
            "Epoch   12/20 Batch 1/3 Cost: 4.470507\n",
            "Epoch   12/20 Batch 2/3 Cost: 0.923753\n",
            "Epoch   12/20 Batch 3/3 Cost: 0.132706\n",
            "Epoch   13/20 Batch 1/3 Cost: 1.450770\n",
            "Epoch   13/20 Batch 2/3 Cost: 4.055174\n",
            "Epoch   13/20 Batch 3/3 Cost: 1.431765\n",
            "Epoch   14/20 Batch 1/3 Cost: 3.468175\n",
            "Epoch   14/20 Batch 2/3 Cost: 3.627177\n",
            "Epoch   14/20 Batch 3/3 Cost: 1.006021\n",
            "Epoch   15/20 Batch 1/3 Cost: 2.649999\n",
            "Epoch   15/20 Batch 2/3 Cost: 0.482021\n",
            "Epoch   15/20 Batch 3/3 Cost: 5.925796\n",
            "Epoch   16/20 Batch 1/3 Cost: 1.667954\n",
            "Epoch   16/20 Batch 2/3 Cost: 3.310692\n",
            "Epoch   16/20 Batch 3/3 Cost: 4.122568\n",
            "Epoch   17/20 Batch 1/3 Cost: 4.719289\n",
            "Epoch   17/20 Batch 2/3 Cost: 2.107971\n",
            "Epoch   17/20 Batch 3/3 Cost: 0.143212\n",
            "Epoch   18/20 Batch 1/3 Cost: 5.055257\n",
            "Epoch   18/20 Batch 2/3 Cost: 0.843501\n",
            "Epoch   18/20 Batch 3/3 Cost: 3.317149\n",
            "Epoch   19/20 Batch 1/3 Cost: 5.118354\n",
            "Epoch   19/20 Batch 2/3 Cost: 1.420750\n",
            "Epoch   19/20 Batch 3/3 Cost: 0.311976\n",
            "Epoch   20/20 Batch 1/3 Cost: 4.522241\n",
            "Epoch   20/20 Batch 2/3 Cost: 1.014165\n",
            "Epoch   20/20 Batch 3/3 Cost: 0.091242\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_var = torch.FloatTensor([[73,80,75]])\n",
        "pred_y = model(new_var)\n",
        "print(pred_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTaGuVLC6GjK",
        "outputId": "d862907e-fc81-45ae-f06f-5d9fd7a8c2b4"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[152.1972]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom Dataset\n",
        "### torch.utils.data.Dataset을 상속받아 직접 custom dataset을 만드는 경우도 있다."
      ],
      "metadata": {
        "id": "KpDLlY0A7gj2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as f\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self):\n",
        "    self.x_data = [[73, 80, 75],\n",
        "                   [93, 88, 93],\n",
        "                   [89, 91, 90],\n",
        "                   [96, 98, 100],\n",
        "                   [73, 66, 70]]\n",
        "    self.y_data = [[152], [185], [180], [196], [142]]\n",
        "  \n",
        "  # 총 데이터 개수 리턴\n",
        "  def __len__(self):\n",
        "    return len(self.x_data)\n",
        "  \n",
        "  # 인덱스를 입력받아 그에 맵핑되는 입출력 데이터를 pytorch의 tensor 형태로 리턴\n",
        "  def __getitem__(self,idx):\n",
        "    x = torch.FloatTensor(self.x_data[idx])\n",
        "    y = torch.FloatTensor(self.y_data[idx])\n",
        "    return x,y\n",
        "\n",
        "dataset = CustomDataset()\n",
        "dataloader = DataLoader(dataset,batch_size=2, shuffle=True)\n",
        "\n",
        "model = torch.nn.Linear(3,1)\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr=1e-5)\n",
        "\n",
        "nb_epochs=20\n",
        "\n",
        "for epoch in range(nb_epochs+1):\n",
        "  for batch_idx, samples in enumerate(dataloader):\n",
        "    x_train, y_train= samples\n",
        "\n",
        "    prediction = model(x_train)\n",
        "\n",
        "    cost = F.mse_loss(prediction,y_train)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print('Epoch {:4d}/{} Batch {}/{} Cost: {:.6f}'.format(\n",
        "        epoch, nb_epochs, batch_idx+1, len(dataloader),\n",
        "        cost.item()\n",
        "        ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIclHA9W7J8c",
        "outputId": "1e447b13-3c80-4da2-fff6-a63ad6d745c6"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/20 Batch 1/3 Cost: 60260.054688\n",
            "Epoch    0/20 Batch 2/3 Cost: 24187.050781\n",
            "Epoch    0/20 Batch 3/3 Cost: 7451.262207\n",
            "Epoch    1/20 Batch 1/3 Cost: 2172.791016\n",
            "Epoch    1/20 Batch 2/3 Cost: 426.008667\n",
            "Epoch    1/20 Batch 3/3 Cost: 176.225464\n",
            "Epoch    2/20 Batch 1/3 Cost: 51.904434\n",
            "Epoch    2/20 Batch 2/3 Cost: 25.064507\n",
            "Epoch    2/20 Batch 3/3 Cost: 25.065657\n",
            "Epoch    3/20 Batch 1/3 Cost: 4.560037\n",
            "Epoch    3/20 Batch 2/3 Cost: 3.363674\n",
            "Epoch    3/20 Batch 3/3 Cost: 13.814692\n",
            "Epoch    4/20 Batch 1/3 Cost: 5.317976\n",
            "Epoch    4/20 Batch 2/3 Cost: 3.416877\n",
            "Epoch    4/20 Batch 3/3 Cost: 7.356547\n",
            "Epoch    5/20 Batch 1/3 Cost: 4.508004\n",
            "Epoch    5/20 Batch 2/3 Cost: 3.371403\n",
            "Epoch    5/20 Batch 3/3 Cost: 13.739931\n",
            "Epoch    6/20 Batch 1/3 Cost: 4.974255\n",
            "Epoch    6/20 Batch 2/3 Cost: 10.525476\n",
            "Epoch    6/20 Batch 3/3 Cost: 1.861449\n",
            "Epoch    7/20 Batch 1/3 Cost: 4.675714\n",
            "Epoch    7/20 Batch 2/3 Cost: 7.297645\n",
            "Epoch    7/20 Batch 3/3 Cost: 2.033331\n",
            "Epoch    8/20 Batch 1/3 Cost: 5.895012\n",
            "Epoch    8/20 Batch 2/3 Cost: 1.140332\n",
            "Epoch    8/20 Batch 3/3 Cost: 13.538191\n",
            "Epoch    9/20 Batch 1/3 Cost: 5.700674\n",
            "Epoch    9/20 Batch 2/3 Cost: 6.141965\n",
            "Epoch    9/20 Batch 3/3 Cost: 5.508123\n",
            "Epoch   10/20 Batch 1/3 Cost: 3.897990\n",
            "Epoch   10/20 Batch 2/3 Cost: 5.306087\n",
            "Epoch   10/20 Batch 3/3 Cost: 8.107234\n",
            "Epoch   11/20 Batch 1/3 Cost: 4.301327\n",
            "Epoch   11/20 Batch 2/3 Cost: 3.394936\n",
            "Epoch   11/20 Batch 3/3 Cost: 13.519895\n",
            "Epoch   12/20 Batch 1/3 Cost: 5.244574\n",
            "Epoch   12/20 Batch 2/3 Cost: 3.222167\n",
            "Epoch   12/20 Batch 3/3 Cost: 11.649989\n",
            "Epoch   13/20 Batch 1/3 Cost: 5.298028\n",
            "Epoch   13/20 Batch 2/3 Cost: 6.344172\n",
            "Epoch   13/20 Batch 3/3 Cost: 7.422499\n",
            "Epoch   14/20 Batch 1/3 Cost: 5.340418\n",
            "Epoch   14/20 Batch 2/3 Cost: 8.463866\n",
            "Epoch   14/20 Batch 3/3 Cost: 9.536765\n",
            "Epoch   15/20 Batch 1/3 Cost: 2.632897\n",
            "Epoch   15/20 Batch 2/3 Cost: 12.472170\n",
            "Epoch   15/20 Batch 3/3 Cost: 3.683230\n",
            "Epoch   16/20 Batch 1/3 Cost: 0.749784\n",
            "Epoch   16/20 Batch 2/3 Cost: 8.051615\n",
            "Epoch   16/20 Batch 3/3 Cost: 7.856175\n",
            "Epoch   17/20 Batch 1/3 Cost: 5.118788\n",
            "Epoch   17/20 Batch 2/3 Cost: 5.330074\n",
            "Epoch   17/20 Batch 3/3 Cost: 9.403128\n",
            "Epoch   18/20 Batch 1/3 Cost: 8.200729\n",
            "Epoch   18/20 Batch 2/3 Cost: 5.760566\n",
            "Epoch   18/20 Batch 3/3 Cost: 4.763951\n",
            "Epoch   19/20 Batch 1/3 Cost: 8.508320\n",
            "Epoch   19/20 Batch 2/3 Cost: 7.676899\n",
            "Epoch   19/20 Batch 3/3 Cost: 6.127695\n",
            "Epoch   20/20 Batch 1/3 Cost: 1.189792\n",
            "Epoch   20/20 Batch 2/3 Cost: 6.009331\n",
            "Epoch   20/20 Batch 3/3 Cost: 10.840729\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lL3EUlZf9r_E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}